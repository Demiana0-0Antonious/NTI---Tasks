{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_P8q1al8WsOv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sigmoid -> puts number in range between 0 and 1"
      ],
      "metadata": {
        "id": "MDNsVIJNYhWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))"
      ],
      "metadata": {
        "id": "GhJJvJmHWtPD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sigmoid Derivative ->\n",
        "We need the derivative for backpropagation."
      ],
      "metadata": {
        "id": "zEHRuq-VY2Cy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_derivative(a):\n",
        "    return a * (1 - a)"
      ],
      "metadata": {
        "id": "Y3H9kzxwWtLh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ReLU (Rectified Linear Unit) ->\n",
        "ReLU keeps positive numbers and replaces negatives with 0 to avoid some problems sigmoid has"
      ],
      "metadata": {
        "id": "QtEYw4DPZJbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(z):\n",
        "    return np.maximum(0, z)"
      ],
      "metadata": {
        "id": "CNK9g8ocWtIu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ReLU Derivative ->\n",
        "The derivative is 1 for positive values and 0 for negative values."
      ],
      "metadata": {
        "id": "Xb4P_FmbZaz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu_derivative(z):\n",
        "    return (z > 0).astype(float)"
      ],
      "metadata": {
        "id": "lpg50ntiWtGI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize Parameters"
      ],
      "metadata": {
        "id": "j0pR1bHZZjl3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We randomly set initial weights and set biases to zero.\n",
        "\n",
        "W1 â†’ connects input layer â†’ hidden layer\n",
        "\n",
        "b1 â†’ bias for hidden layer\n",
        "\n",
        "W2 â†’ connects hidden layer â†’ output layer\n",
        "\n",
        "b2 â†’ bias for output layer"
      ],
      "metadata": {
        "id": "EnHGOEE1ZkJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_params(input_dim, hidden_dim, seed=42):\n",
        "    np.random.seed(seed)\n",
        "    W1 = np.random.randn(input_dim, hidden_dim) * 0.01\n",
        "    b1 = np.zeros((1, hidden_dim))\n",
        "    W2 = np.random.randn(hidden_dim, 1) * 0.01\n",
        "    b2 = np.zeros((1, 1))\n",
        "    return W1, b1, W2, b2"
      ],
      "metadata": {
        "id": "GQXPyfr0WtDe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Forward Propagation"
      ],
      "metadata": {
        "id": "usxEOWyfaCY0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We feed input data through the network to get predictions.\n",
        "\n",
        "Z1 = XÂ·W1 + b1\n",
        "\n",
        "A1 = ReLU(Z1) â†’ hidden layer activation\n",
        "\n",
        "Z2 = A1Â·W2 + b2\n",
        "\n",
        "A2 = Sigmoid(Z2) â†’ output layer activation (probability)"
      ],
      "metadata": {
        "id": "0OrRrDsIaH2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(X, W1, b1, W2, b2):\n",
        "    Z1 = np.dot(X, W1) + b1\n",
        "    A1 = relu(Z1)\n",
        "    Z2 = np.dot(A1, W2) + b2\n",
        "    A2 = sigmoid(Z2)\n",
        "    return Z1, A1, Z2, A2"
      ],
      "metadata": {
        "id": "D62pjd0qaGxl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss Function â€” Binary Cross Entropy ->\n",
        "Measures how well our predictions match the labels."
      ],
      "metadata": {
        "id": "3hSu2-rOaaIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss = âˆ’\n",
        "m\n",
        "1\n",
        "â€‹\n",
        " âˆ‘[ylog(A2)+(1âˆ’y)log(1âˆ’A2)]"
      ],
      "metadata": {
        "id": "OQXY9EC1ahtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(y, A2):\n",
        "    m = y.shape[0]\n",
        "    loss = -np.mean(y * np.log(A2 + 1e-8) + (1 - y) * np.log(1 - A2 + 1e-8))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "CcbtcxOVWtAu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We add 1e-8 to avoid log(0) errors**"
      ],
      "metadata": {
        "id": "FptgVun9a3kp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backward Propagation"
      ],
      "metadata": {
        "id": "Y7-rnIfAa_Sn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we find gradients to know how to update weights."
      ],
      "metadata": {
        "id": "cZg8Njo_bG6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output layer error:\n",
        "\n",
        "ð‘‘\n",
        "ð‘\n",
        "2\n",
        "=\n",
        "ð´\n",
        "2\n",
        "âˆ’\n",
        "ð‘¦\n",
        "dZ2=A2âˆ’y\n",
        "\n",
        "\n",
        "Then:\n",
        "\n",
        "ð‘‘\n",
        "ð‘Š\n",
        "2\n",
        "=\n",
        "1\n",
        "ð‘š\n",
        "ð´\n",
        "1\n",
        "ð‘‡\n",
        "â‹…\n",
        "ð‘‘\n",
        "ð‘\n",
        "2\n",
        "dW2=\n",
        "m\n",
        "1\n",
        "â€‹\n",
        " A1\n",
        "T\n",
        " â‹…dZ2\n",
        "ð‘‘\n",
        "ð‘\n",
        "2\n",
        "=\n",
        "1\n",
        "ð‘š\n",
        "âˆ‘\n",
        "ð‘‘\n",
        "ð‘\n",
        "2\n",
        "\n",
        "\n",
        "db2=\n",
        "m\n",
        "1\n",
        "â€‹\n",
        " âˆ‘dZ2\n",
        "\n",
        "\n",
        "Hidden layer error:\n",
        "\n",
        "ð‘‘\n",
        "ð‘\n",
        "1\n",
        "=\n",
        "(\n",
        "ð‘‘\n",
        "ð‘\n",
        "2\n",
        "â‹…\n",
        "ð‘Š\n",
        "2\n",
        "ð‘‡\n",
        ")\n",
        "â‹…\n",
        "ð‘…\n",
        "ð‘’\n",
        "ð¿\n",
        "ð‘ˆ\n",
        "â€²\n",
        "(\n",
        "ð‘\n",
        "1\n",
        ")\n",
        "dZ1=(dZ2â‹…W2\n",
        "T\n",
        " )â‹…ReLU\n",
        "â€²\n",
        " (Z1)\n",
        "\n",
        "\n",
        "ð‘‘\n",
        "ð‘Š\n",
        "1\n",
        "=\n",
        "1\n",
        "ð‘š\n",
        "ð‘‹\n",
        "ð‘‡\n",
        "â‹…\n",
        "ð‘‘\n",
        "ð‘\n",
        "1\n",
        "dW1=\n",
        "m\n",
        "1\n",
        "â€‹\n",
        " X\n",
        "T\n",
        " â‹…dZ1\n",
        "ð‘‘\n",
        "ð‘\n",
        "1\n",
        "=\n",
        "1\n",
        "ð‘š\n",
        "âˆ‘\n",
        "ð‘‘\n",
        "ð‘\n",
        "1\n",
        "\n",
        "\n",
        "db1=\n",
        "m\n",
        "1\n",
        "â€‹\n",
        " âˆ‘dZ1"
      ],
      "metadata": {
        "id": "fb1Jj8IGbR0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backward(X, y, Z1, A1, A2, W2):\n",
        "    m = X.shape[0]\n",
        "    dZ2 = A2 - y\n",
        "    dW2 = np.dot(A1.T, dZ2) / m\n",
        "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
        "    dZ1 = np.dot(dZ2, W2.T) * relu_derivative(Z1)\n",
        "    dW1 = np.dot(X.T, dZ1) / m\n",
        "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
        "    return dW1, db1, dW2, db2"
      ],
      "metadata": {
        "id": "5uTxGlZZZg1k"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Update Parameters (Gradient Descent)**"
      ],
      "metadata": {
        "id": "gpHGy4apcHK1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We move weights against the gradient to minimize loss."
      ],
      "metadata": {
        "id": "EY8vQtdwcG7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, lr):\n",
        "    W1 -= lr * dW1\n",
        "    b1 -= lr * db1\n",
        "    W2 -= lr * dW2\n",
        "    b2 -= lr * db2\n",
        "    return W1, b1, W2, b2"
      ],
      "metadata": {
        "id": "SYtdVMHVZgyH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Loop** ->\n",
        "We connect all pieces to train our network."
      ],
      "metadata": {
        "id": "czPrOvP1cb2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Toy dataset\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "# Generate data\n",
        "X, y = make_moons(n_samples=200, noise=0.2, random_state=42)\n",
        "y = y.reshape(-1, 1)\n",
        "\n",
        "# Initialize parameters\n",
        "W1, b1, W2, b2 = init_params(input_dim=2, hidden_dim=4)\n",
        "\n",
        "# Training\n",
        "epochs = 1000\n",
        "lr = 0.1\n",
        "\n",
        "for i in range(epochs):\n",
        "    # Forward\n",
        "    Z1, A1, Z2, A2 = forward(X, W1, b1, W2, b2)\n",
        "\n",
        "    # Loss\n",
        "    loss = compute_loss(y, A2)\n",
        "\n",
        "    # Backward\n",
        "    dW1, db1, dW2, db2 = backward(X, y, Z1, A1, A2, W2)\n",
        "\n",
        "    # Update\n",
        "    W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, lr)\n",
        "\n",
        "    # Print progress\n",
        "    if i % 100 == 0:\n",
        "        print(f\"Epoch {i}, Loss: {loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyIYgN3ocbg5",
        "outputId": "adad7569-ea42-4c3c-a51a-3214e85f20fa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6932\n",
            "Epoch 100, Loss: 0.6925\n",
            "Epoch 200, Loss: 0.6542\n",
            "Epoch 300, Loss: 0.3816\n",
            "Epoch 400, Loss: 0.3235\n",
            "Epoch 500, Loss: 0.3145\n",
            "Epoch 600, Loss: 0.3127\n",
            "Epoch 700, Loss: 0.3121\n",
            "Epoch 800, Loss: 0.3119\n",
            "Epoch 900, Loss: 0.3117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**END  ;)**"
      ],
      "metadata": {
        "id": "KRXfVp-Kc22s"
      }
    }
  ]
}